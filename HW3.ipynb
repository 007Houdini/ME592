{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de5584e-1d19-482c-b578-8c8ac1003f0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Homework 3**\n",
    "### Engineering Image Analysis - Combustion Images\n",
    "#### Step 1 - Train 2D CNN for Classifying Flames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ab3b165-7a4b-4567-a929-4e97334afe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_set_x', 'test_set_y', 'train_set_x', 'train_set_y', 'valid_set_x', 'valid_set_y']\n",
      "(25000, 54000)\n",
      "(54000, 1)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "#Load the data from the .mat file \n",
    "#NOTE: x data are single channel images sized at 250x100 pixels \n",
    "#      y data are classifiers for the x images stating stable (1) and unstable (0)\n",
    "\n",
    "with h5py.File('combustion_img_13.mat', 'r') as f:\n",
    "    print(list(f.keys())) #Print the available keys in the file\n",
    "    train_set_x = np.array(f['train_set_x'])\n",
    "    train_set_y = np.array(f['train_set_y'])\n",
    "    valid_set_x = np.array(f['valid_set_x'])\n",
    "    valid_set_y = np.array(f['valid_set_y'])\n",
    "    test_set_x = np.array(f['test_set_x'])\n",
    "    test_set_y = np.array(f['test_set_y'])    \n",
    "\n",
    "print(train_set_x.shape)\n",
    "print(train_set_y.shape)\n",
    "\n",
    "#By analyzing data in matlab, found a split point between y data 0 & 1 values to determine which value corresponds to stable/unstable\n",
    "imgs = []\n",
    "for i in range(5995, 6005):           \n",
    "    sample_img = train_set_x[:, i]\n",
    "    #print(f\"initial shape: {sample_img.shape}\")\n",
    "    sample_img = sample_img.reshape(250, 100)\n",
    "    #print(f\"next shape: {sample_img.shape}\")\n",
    "    imgs.append(sample_img)\n",
    "    \n",
    "stacked = np.hstack(imgs)\n",
    "# imshow(stacked, cmap='hot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e0d1541-5b93-42dc-aa82-24db7caabf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 01:36:52.143661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 01:36:52.804785: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-04 01:36:52.804813: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-04 01:36:54.406588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 01:36:54.406666: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-04 01:36:54.406672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data via normalization and converting the labels to one-hot encoding:\n",
    "import tensorflow as tf\n",
    "\n",
    "# Preprocess the data\n",
    "train_set_x = train_set_x.astype('float32') / 255\n",
    "valid_set_x= valid_set_x.astype('float32') / 255\n",
    "test_set_x = test_set_x.astype('float32') / 255\n",
    "\n",
    "test_set_y = tf.keras.utils.to_categorical(test_set_y, num_classes=2)\n",
    "valid_set_y = tf.keras.utils.to_categorical(valid_set_y, num_classes=2)\n",
    "test_set_y = tf.keras.utils.to_categorical(test_set_y, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645eb763-7213-4015-9137-50785af2d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(250, 100, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_set_x, train_set_y, batch_size=32, epochs=50, validation_data=(valid_set_x, valid_set_y))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_set_x, test_set_y)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05741f19-c478-4fc2-b6ea-df740f18f5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3991387-f33b-48e1-9faf-3828a83e6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# # Preprocess the data\n",
    "# x_train = train_set_x.astype('float32') / 255\n",
    "# x_val = valid_set_x.astype('float32') / 255\n",
    "# x_test = test_set_x.astype('float32') / 255\n",
    "\n",
    "# # Define the CNN model architecture\n",
    "# model = Sequential([\n",
    "#     Conv2D(32, (3, 3), activation='relu', input_shape=(100, 250, 1)),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Conv2D(64, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Conv2D(128, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Flatten(),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model with early stopping based on validation loss\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "# model.fit(x_train, train_set_y, epochs=20, batch_size=32, validation_data=(valid_set_x, valid_set_y),\n",
    "#           callbacks=[early_stop])\n",
    "\n",
    "# # Evaluate the model on the testing set\n",
    "# test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "# print(f'Testing loss: {test_loss}, Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eccdd1b-090e-4a9c-b8b9-7dd0a963234d",
   "metadata": {},
   "source": [
    "#### Step 2 - Train an autoencoder to allow a sequential model to operate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4b962-351e-48c0-9e98-39bdeae10cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2:\n",
    "    \n",
    "# with h5py.File('combustion_img_13.mat', 'r') as f:\n",
    "#     train_set_x = np.array(f['train_set_x'])\n",
    "#     valid_set_x = np.array(f['valid_set_x'])\n",
    "#     test_set_x = np.array(f['test_set_x'])\n",
    "    \n",
    "# x_train = train_set_x.astype('float32') / 255.\n",
    "# x_val = valid_set_x.astype('float32') / 255.\n",
    "# x_test = test_set_x.astype('float32') / 255.\n",
    "\n",
    "# x_train = x_train.reshape(-1, 250, 100, 1)\n",
    "# x_val = x_val.reshape(-1, 250, 100, 1)\n",
    "# x_test = x_test.reshape(-1, 250, 100, 1)\n",
    "\n",
    "\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
    "\n",
    "# input_img = Input(shape=(250, 100, 1))\n",
    "\n",
    "# x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "# x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "# x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "# encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# x = Conv2DTranspose(128, (3, 3), strides=(2, 2), activation='relu', padding='same')(encoded)\n",
    "# x = Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "# x = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "# decoded = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# autoencoder = Model(input_img, decoded)\n",
    "# autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd798cdc-bcff-4b7e-a3a3-ae6a12d4d7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07db8062-b08a-41c8-956d-18e77c4fa3d1",
   "metadata": {},
   "source": [
    "# TEST CODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc673aa-d274-43a1-b2ba-186079aeadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.io as sio    \n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load the data\n",
    "# # data = sio.loadmat('combustion_img_13.mat')  #NOTE: Found out scipy.io doesn't support Matlab v7.3 data files\n",
    "\n",
    "# import h5py\n",
    "# with h5py.File('combustion_img_13.mat', 'r') as f:\n",
    "\n",
    "# # print(list(f.keys())) #Print the available keys in the file\n",
    "    \n",
    "# # Get the training, validation, and testing sets\n",
    "#     train_set_x = np.array(f['train_set_x'])\n",
    "#     train_set_y = np.array(f['train_set_y'])\n",
    "#     valid_set_x = np.array(f['valid_set_x'])\n",
    "#     valid_set_y = np.array(f['valid_set_y'])\n",
    "#     test_set_x = np.array(f['test_set_x'])\n",
    "#     test_set_y = np.array(f['test_set_y'])  \n",
    "\n",
    "# # Define the classes\n",
    "# classes = ['stable', 'unstable']\n",
    "\n",
    "# # Visualize a few images\n",
    "# # fig, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "# # axs = axs.ravel()\n",
    "# # for i in range(10):\n",
    "# #     axs[i].imshow(train_set_x[i], cmap='gray')\n",
    "# #     axs[i].set_title(classes[train_set_y[i][0]])\n",
    "# #     axs[i].axis('off')\n",
    "# plt.imshow(train_set_x[0], cmap = 'gray')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6537137c-e0d5-45f4-80e4-270c8ba593d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
